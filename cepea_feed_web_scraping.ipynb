{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9cf891-538d-4a1c-9cc7-675f27145ce1",
   "metadata": {},
   "source": [
    "# CEPEA - Diárias do Mercado - Web Scraping\n",
    "\n",
    "Esse _script_ realizará o _web scraping_ no site do CEPEA capturando todos as publicações de \"Diárias de Mercado\" relacionados a Acúcar e Etanol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e3bdd-df5f-4f27-aace-f4e5fc564ff4",
   "metadata": {},
   "source": [
    "## 1. Requisitos\n",
    "\n",
    "Vamos usar o [Beautiful Soup](https://pypi.org/project/beautifulsoup4/) (`bsf4`) para realizar a leitura do HTML e o [requests](https://pypi.org/project/requests/) para acessar websites a partir do HTTP.\n",
    "\n",
    "## 2. Bibliotecas\n",
    "\n",
    "* Beautiful Soup (`bsf4`)\n",
    "* `requests`\n",
    "* `pandas`\n",
    "* `os`\n",
    "* `time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08393371-c866-4f7f-a690-4ed4d39b1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento das bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947002b8-3672-43e1-a3e0-0565542fb9c5",
   "metadata": {},
   "source": [
    "## 3. Carregamento do Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c594f1-fcc0-47e9-91eb-511b4908bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir o caminho completo para o arquivo CSV\n",
    "base_dir = os.getcwd()  # Diretório atual\n",
    "data_dir = os.path.join(base_dir, '01-data')  # Diretório '01-data' dentro do diretório atual\n",
    "\n",
    "# Carregar o DataFrame de Feed a partir do arquivo CSV\n",
    "df_merge = pd.read_csv(os.path.join(data_dir, '2024-08-11 cepea_feed_rss_merge.csv'), encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062629af-b34f-49d9-a101-966c68664599",
   "metadata": {},
   "source": [
    "## 4. Função\n",
    "\n",
    "Esta função itera a cada linha do banco de dados. A coluna URL armazena o destino a ser visitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73f7200-feb9-4473-88ee-e2bad03b4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_update_df(df, output_filename):\n",
    "    \"\"\"\n",
    "    Itera sobre as URLs no DataFrame, extrai o texto desejado de cada URL e adiciona\n",
    "    o texto extraído como uma nova coluna ao DataFrame. Em seguida, salva o DataFrame atualizado em um arquivo CSV.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df: DataFrame contendo as URLs para processar.\n",
    "    - output_filename: Nome do arquivo CSV de saída (incluindo o caminho, se necessário).\n",
    "    \"\"\"\n",
    "    # Lista para armazenar os textos extraídos\n",
    "    texts = []\n",
    "\n",
    "    # Iterar sobre cada linha do DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['URL']\n",
    "\n",
    "        # Definir um cabeçalho User-Agent\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Fazer a requisição HTTP para a página\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            # Verificar se a requisição foi bem sucedida\n",
    "            if response.status_code == 200:\n",
    "                # Parsear o conteúdo HTML da página com o BeautifulSoup\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                \n",
    "                # Localizar o div que contém o texto de interesse\n",
    "                text_div = soup.find('div', class_='imagenet-ma-b imagenet-fl imagenet-col-12 imagenet-table-responsiva')\n",
    "                \n",
    "                if text_div:\n",
    "                    # Extrair o texto do div\n",
    "                    text = text_div.get_text(strip=True)\n",
    "                    texts.append(text)\n",
    "                else:\n",
    "                    texts.append(\"Texto não encontrado\")\n",
    "            else:\n",
    "                print(f\"Erro ao acessar o URL {url}: {response.status_code}\")\n",
    "                texts.append(\"Erro ao acessar a página\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o URL {url}: {e}\")\n",
    "            texts.append(\"Erro ao processar a página\")\n",
    "\n",
    "    # Faz uma cópia para não dar o Warning\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Adicionar a nova coluna 'Texto' ao DataFrame\n",
    "    df_copy['Texto'] = texts\n",
    "\n",
    "    # Caminho completo para o arquivo de exportação\n",
    "    file_path = os.path.join(\"01-data\", time.strftime('%Y-%m-%d') + ' ' + output_filename)\n",
    "\n",
    "    # Salvar o DataFrame atualizado em um novo arquivo CSV\n",
    "    df_copy.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Exibir o DataFrame\n",
    "    return(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74386d-acbf-4b23-a9c4-6c9553b0915e",
   "metadata": {},
   "source": [
    "## 5. Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe9c3f9-4b2c-40f4-ad3d-e2f88f68046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução da função para obter as publicações em uma banco de dados único\n",
    "df_databse = extract_texts_and_update_df(df_merge, \"cepea_feed_database.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
